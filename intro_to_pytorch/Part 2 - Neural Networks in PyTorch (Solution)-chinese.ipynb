{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c81f038c",
   "metadata": {},
   "source": [
    "# 通过 PyTorch 构建神经网络\n",
    "\n",
    "深度学习网络一般量级都很大，包含数百个层级，这也是为什么叫“深度”学习网络。你可以像在上个 notebook 展示的一样，仅使用权重矩阵构建深度网络，但是这通常很繁琐并且不好实施。PyTorch 有一个很方便的模块 `nn`，可以有效地构建大型神经网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e6c4b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary packages\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBacked.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch \n",
    "\n",
    "import helper\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a445d3e7",
   "metadata": {},
   "source": [
    " 现在我们要构建一个大型网络，并用它解决识别图像中的文字的这一难题。我们将使用 MNIST 数据集，这个数据集由灰色的手写数字组成。每个图像都是 28x28，如以下示例所示：\n",
    "\n",
    "<img src='assets/mnist.png'>\n",
    "\n",
    "我们的目标是构建一个神经网络，可以预测图像中的数字。\n",
    "\n",
    "首先，我们需要获取数据集。这些数据位于 `torchvision` 软件包中。以下代码将下载 MNIST 数据集，然后为我们创建训练数据集和测试数据集。不用太在意细节内容，稍后会详细学习的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c68bb594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /home/zhanghao/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06822af8caed4e5eb9e4fc5e17bbd3d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/zhanghao/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to /home/zhanghao/.pytorch/MNIST_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /home/zhanghao/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf95cedf938d4ba48c1a6103db2fbeb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/zhanghao/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to /home/zhanghao/.pytorch/MNIST_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /home/zhanghao/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ccf6e2ed424584b4b1d8e3c1d30602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/zhanghao/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to /home/zhanghao/.pytorch/MNIST_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /home/zhanghao/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a90aaba90d343cfa8e32c434cf5aff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/zhanghao/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /home/zhanghao/.pytorch/MNIST_data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Run this cell\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72cd99c",
   "metadata": {},
   "source": [
    "我们将训练数据加载到 `trainloader` 中，并使用 `iter(trainloader)` 使其变成迭代器。之后，我们将用它循环访问数据集以进行训练，例如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff5e2f4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (153283872.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_1064927/153283872.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    ## do things with images and labels\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "for image, label in trainloader:\n",
    "    ## do things with images and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c4def6",
   "metadata": {},
   "source": [
    "我在创建 `trainloader` 时，将批次大小设为 64，并设置为 `shuffle=True`。批次大小是指我们在一次迭代中从数据加载器获取并经过网络的图像数量。`shuffle=True` 表示每次重新访问数据加载器时，随机重排数据集。但是现在我仅获取第一批数据，以便查看数据。从下方可以看出，`images` 是一个张量，大小为 `(64, 1, 28, 28)`。因此，每批有 64 个图像，图像有 1 个颜色通道，共有 28x28 个图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c104d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a047e4",
   "metadata": {},
   "source": [
    "下面是一个图像示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6250dfdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d30f5b3",
   "metadata": {},
   "source": [
    "![png](output_7_0.png)\n",
    "\n",
    "\n",
    "首先，我们要使用权重矩阵和矩阵乘法，用此数据集构建一个简单的网络。然后，我们将学习如何使用 PyTorch 的 `nn` 模块构建该网络。\n",
    "\n",
    "神经网络又称为*全连接*或*密集*网络。一个层级中的每个单元都与下个层级中的每个单元相连。在全连接网络中，每个层级的输入必须是一维向量（可以作为一批样本堆叠为二维张量）。但是，我们的图像是 28x28 二维张量，因此我们需要将其转换为一维向量。考虑到大小问题，我们需要将形状为 `(64, 1, 28, 28)` 的批次图像变形为 `(64, 784)`，784 等于 28 x 28。这一步通常称为*扁平化*，我们将二维图像扁平化为一维向量。\n",
    "\n",
    "之前，我们试过了构建具有一个输出单元的简单网络。现在，我们需要 10 个输出单元，每个数字对应一个单元。如果要预测出图像中显示的数字，我们必须计算该图像属于任何数字或类别的概率。我们会得到一个离散概率分布，告诉我们图像最有可能属于哪个类别。这就是说，我们需要 10 个输出单元，对应 10 个类别（数字）。下面讲解如何将网络输出转换为概率分布。\n",
    "\n",
    "> **练习：**将 `images`扁平化。然后构建一个多层网络，有 784 个输入单元、256 个隐藏单元和 10 个输出单元，并对权重和偏差使用随机张量。目前，我们对隐藏层使用 S 型激活函数。输出层暂时不需要激活函数，下一步我们将添加计算概率分布的激活函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e80df560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3330e+01,  3.2714e+00,  1.9392e+00, -5.6738e+00, -8.6151e+00,\n",
       "         -5.5143e+00, -3.4845e+01,  1.0504e+01, -4.7842e+00, -2.6091e+00],\n",
       "        [-1.7182e+01,  8.6651e-01,  4.1029e+00, -9.4886e-02, -1.0270e+01,\n",
       "         -1.3515e+01, -2.4842e+01, -4.4554e-01, -5.8787e+00, -5.5304e+00],\n",
       "        [-1.2459e+01,  5.2164e-01, -6.0287e+00, -7.4470e+00,  3.2531e-02,\n",
       "         -1.6654e-01, -1.4557e+01,  5.1409e+00, -1.3022e+01, -2.4316e+00],\n",
       "        [-2.1909e+01, -5.6417e+00,  1.4123e+00, -2.5683e+00, -1.1528e+01,\n",
       "         -5.6577e+00, -1.9717e+01,  3.1358e+00, -7.0667e+00, -1.4464e+00],\n",
       "        [-3.8581e+00,  8.3600e+00, -7.7744e+00,  1.2372e+01, -1.5214e+01,\n",
       "         -1.2352e+01, -1.8109e+01,  2.1590e+01,  2.4696e+00,  4.2103e-02],\n",
       "        [-1.0319e+01,  6.7724e+00, -3.9803e+00, -3.2709e+00, -8.2420e+00,\n",
       "         -6.8757e+00, -2.0178e+01,  6.9778e+00, -4.8825e+00, -8.1934e+00],\n",
       "        [ 4.7543e-01,  7.7263e+00, -8.1175e-01,  8.7420e+00, -7.5917e+00,\n",
       "         -1.5677e+01, -2.1076e+01,  4.2093e+00, -1.2032e+00, -5.6210e+00],\n",
       "        [-1.8626e+01, -4.6262e+00,  7.1377e-01, -8.1341e+00, -4.5197e+00,\n",
       "         -1.4555e+00, -1.8156e+01, -9.5666e+00, -1.5409e+01,  3.8674e+00],\n",
       "        [-1.0228e+01, -1.5503e+00, -9.9069e+00,  4.4730e+00, -1.0369e+01,\n",
       "         -6.4184e+00, -2.3440e+01,  8.9017e+00,  2.7688e+00, -3.8220e+00],\n",
       "        [-8.2596e+00,  1.3250e+00, -6.2145e+00, -1.3504e+00, -1.4957e+01,\n",
       "         -1.4168e+01, -1.8159e+01, -5.1858e+00, -3.5822e+00,  1.7846e+00],\n",
       "        [-1.2673e+01,  8.5008e+00, -4.1481e+00, -7.3742e+00, -1.6068e+01,\n",
       "         -4.4865e-01, -2.0162e+01,  7.6159e+00, -6.8255e+00, -7.1094e-01],\n",
       "        [-1.0283e+01,  3.8848e+00, -4.0896e+00,  8.9849e-01, -7.0278e+00,\n",
       "         -3.0867e+00, -2.7477e+01,  1.2708e+01, -4.0792e+00, -7.2182e+00],\n",
       "        [-1.8911e+01,  1.0839e+00, -6.2796e+00, -1.6810e+00, -5.8197e+00,\n",
       "          3.1332e+00, -2.4403e+01, -2.3872e+00, -9.3598e+00,  6.4073e+00],\n",
       "        [-6.1777e+00,  6.1122e+00,  5.3847e+00, -3.3786e+00, -6.8389e+00,\n",
       "         -4.7318e+00, -2.7545e+01,  1.3414e+01, -5.0831e-01, -2.5795e+00],\n",
       "        [-1.4507e+01,  1.4442e+01, -5.6713e+00,  1.4749e+00, -2.2688e+00,\n",
       "         -1.1414e+01, -1.7012e+01,  1.5523e+01,  5.3241e+00, -8.6089e+00],\n",
       "        [-1.4393e+01,  6.5790e+00,  1.8687e+00, -3.9929e+00, -3.9748e+00,\n",
       "         -4.3187e+00, -2.0929e+01,  1.9915e+00, -8.3409e+00, -6.2519e+00],\n",
       "        [-1.1460e+01,  1.3549e+01, -3.3124e+00,  1.2694e+00, -5.6615e+00,\n",
       "         -1.3734e+01, -2.0067e+01,  8.9632e+00, -3.3742e+00, -4.4768e+00],\n",
       "        [-1.0944e+01,  1.0239e+01,  3.7847e+00, -4.4544e+00, -2.0584e+01,\n",
       "         -1.2966e+00, -2.1977e+01,  6.9906e+00, -3.2816e+00, -1.4236e-01],\n",
       "        [-8.2440e+00,  1.1623e-01, -3.4559e+00, -4.7792e+00, -1.0944e+01,\n",
       "         -6.8742e+00, -2.0182e+01, -6.3522e+00, -1.0882e+01, -1.2855e+01],\n",
       "        [-1.7834e+01,  5.9547e+00, -6.0778e+00,  2.2073e-01, -7.9082e+00,\n",
       "         -1.2745e+01, -1.5761e+01, -1.8234e+00,  3.9618e+00, -7.2817e+00],\n",
       "        [-9.2709e+00,  2.3394e+00,  2.1420e+00, -5.5990e+00, -9.3937e+00,\n",
       "         -5.0663e+00, -2.4120e+01, -1.5588e+00, -7.3911e+00,  2.5720e+00],\n",
       "        [-1.4358e+01, -5.1881e+00, -8.9000e+00, -6.0787e+00, -6.1378e+00,\n",
       "         -3.4695e+00, -2.5733e+01,  9.8085e+00,  2.9089e+00, -2.6252e-01],\n",
       "        [-2.0191e+01,  8.8134e-01, -3.8827e+00, -4.1214e+00, -8.2158e+00,\n",
       "          4.1771e+00, -1.7325e+01,  6.6252e+00, -1.4372e+01, -6.6464e+00],\n",
       "        [-1.6905e+01,  8.2845e+00, -3.4107e+00,  5.1577e+00, -6.9755e+00,\n",
       "          3.5976e+00, -2.4203e+01, -3.1453e+00, -2.7461e+00, -5.3686e+00],\n",
       "        [-1.5699e+01, -1.4473e+00, -1.3555e+00,  5.4313e+00, -5.1354e+00,\n",
       "         -1.7556e+01, -5.3418e+00,  7.4009e-01, -4.3034e+00, -5.2020e+00],\n",
       "        [-1.8807e+01,  1.1496e+00, -1.6005e+00,  3.2731e+00, -9.4774e+00,\n",
       "         -3.1313e+00, -1.3202e+01,  1.6473e+01, -5.7394e+00, -8.9248e+00],\n",
       "        [-8.9643e+00,  7.7481e+00, -3.1604e+00,  3.1930e+00, -2.1098e+01,\n",
       "         -2.5816e+00, -1.5823e+01,  1.0965e+01, -5.7911e+00,  1.5550e+00],\n",
       "        [-7.1383e+00,  1.2385e+00,  2.2679e+00, -8.5160e-01, -1.7506e+01,\n",
       "         -1.0147e+01, -2.6260e+01,  3.5684e+00, -1.6176e+01,  1.9462e+00],\n",
       "        [-1.5571e+01, -3.0854e+00, -7.8669e-01, -8.0964e+00, -8.3497e+00,\n",
       "         -9.0618e+00, -2.3269e+01, -7.1351e+00, -1.5535e+01,  1.4715e+00],\n",
       "        [-1.4713e+01,  2.2143e-01, -2.5387e+00,  9.3202e+00,  3.1415e+00,\n",
       "         -4.1416e+00, -1.6472e+01,  9.3439e+00, -9.3374e+00, -2.1101e+00],\n",
       "        [-1.2188e+01,  1.1831e+01, -5.7422e+00,  4.3480e+00, -7.7754e+00,\n",
       "         -2.6679e+00, -3.1337e+01, -6.3300e+00, -1.5066e+01, -6.1684e+00],\n",
       "        [-1.3916e+01,  8.6897e+00,  1.5239e+00, -1.7953e+00, -4.2212e+00,\n",
       "         -5.8106e+00, -2.1178e+01,  9.2245e+00,  2.6716e+00, -5.9206e+00],\n",
       "        [-5.3739e-01,  3.5352e+00, -1.6434e+00, -3.4293e+00, -5.1742e+00,\n",
       "         -7.3140e+00, -3.3461e+01,  6.0831e+00, -2.6583e+00,  4.2357e-01],\n",
       "        [-1.5379e+01,  2.2306e+00, -3.1791e+00, -3.5301e+00, -6.1357e+00,\n",
       "          4.7001e+00, -2.8993e+01, -8.3218e-01,  6.8205e+00, -2.7503e+00],\n",
       "        [-1.1356e+01,  3.8569e+00, -4.8772e+00,  1.9190e+00, -5.6865e+00,\n",
       "         -1.6216e+01, -1.1167e+01,  3.5699e+00, -9.3543e+00,  3.4312e-01],\n",
       "        [-1.6199e+01, -5.5587e+00, -3.1303e+00, -6.3830e+00, -7.1700e+00,\n",
       "         -5.4259e+00, -2.3652e+01,  5.8403e+00, -1.8563e+00, -1.0975e+01],\n",
       "        [-1.2063e+01, -2.7352e+00,  3.6067e-02, -1.6448e+00, -9.0116e+00,\n",
       "         -1.0807e+01, -2.1062e+01,  1.4218e+01, -7.9108e+00,  1.0683e+00],\n",
       "        [-4.4060e+00,  4.5250e+00, -6.8602e+00,  1.6308e+01, -1.1496e+01,\n",
       "         -8.9562e+00, -2.2764e+01, -7.8956e+00, -5.3066e+00, -1.5066e+00],\n",
       "        [-1.2332e+01, -3.7759e-01, -2.2140e+00, -2.1678e+00, -1.2775e+01,\n",
       "          2.0976e+00, -2.1217e+01, -8.6395e+00, -7.0138e+00, -9.9520e+00],\n",
       "        [-1.1097e+01,  3.2636e+00,  4.0682e-01,  9.8447e+00, -1.7140e+01,\n",
       "         -1.5955e+01, -1.9015e+00,  5.4414e+00,  5.9803e-02,  3.9936e-01],\n",
       "        [-1.1439e+01, -5.1481e+00, -1.0072e+00, -2.3741e+00, -2.2368e+00,\n",
       "         -1.0149e+01, -1.8424e+01,  1.9314e+00,  1.2094e+00, -6.6779e+00],\n",
       "        [-2.3778e+01,  1.7648e+00, -2.1500e+00, -4.1873e+00, -1.5497e+01,\n",
       "          7.8600e-01, -1.7975e+01, -8.5466e+00, -1.2802e+01,  3.9774e+00],\n",
       "        [-1.6679e+01, -4.0691e+00, -3.7363e-01, -1.1297e+01, -4.0058e+00,\n",
       "         -2.7743e+00, -1.2098e+01, -1.0789e+00, -1.5105e+01, -1.5838e+00],\n",
       "        [-1.2920e+01,  2.2752e+00, -9.0819e-01, -2.0682e+00, -1.4022e+01,\n",
       "         -4.6821e+00, -2.4181e+01,  4.6515e+00, -1.7874e+01, -6.4134e+00],\n",
       "        [-5.9492e+00,  5.7668e+00, -6.3942e+00, -5.6937e+00, -5.5521e+00,\n",
       "         -8.7873e+00, -2.4265e+01,  5.4123e+00, -3.9154e+00, -3.9684e+00],\n",
       "        [-3.8951e+00,  1.9506e+00, -4.4161e+00, -8.4760e+00, -7.9123e+00,\n",
       "         -5.5729e+00, -2.0242e+01,  6.5856e+00,  1.9392e+00, -8.3573e+00],\n",
       "        [-1.0655e+01,  2.8086e+00, -1.1949e+00,  3.4556e+00, -1.5119e+01,\n",
       "         -8.3394e+00, -2.8297e+01, -1.0587e+01, -7.6482e+00, -7.8267e+00],\n",
       "        [-9.6886e+00,  9.0412e-01, -3.7512e+00,  3.7857e+00, -1.0794e+01,\n",
       "          2.7358e+00, -2.4397e+01, -7.4265e+00, -1.2404e+01,  2.4158e+00],\n",
       "        [-1.4820e+01, -2.4112e+00, -4.6251e+00,  9.2214e-02, -1.5462e+01,\n",
       "         -1.0110e+01, -2.6381e+01,  4.0479e+00,  5.1837e+00,  8.2346e-01],\n",
       "        [-8.0873e+00,  1.0683e+01, -1.4298e+00,  4.1636e+00, -8.2820e+00,\n",
       "         -6.3622e+00, -1.9296e+01,  1.1374e+01, -5.7698e+00, -2.8774e+00],\n",
       "        [-3.3713e+00, -7.5916e-01,  7.6595e+00, -4.0131e+00, -7.0426e+00,\n",
       "         -8.5782e+00, -2.9635e+01,  5.7608e+00, -4.7720e+00,  1.8153e+00],\n",
       "        [-1.0651e+01,  7.1063e+00,  2.5589e+00, -4.3376e+00, -1.0551e+01,\n",
       "         -4.0373e+00, -2.2239e+01,  8.0472e+00, -1.9402e+00,  1.6405e-02],\n",
       "        [-1.4002e+01, -4.5327e+00, -3.6056e+00, -3.0328e+00, -6.8911e+00,\n",
       "         -3.3463e+00, -1.7913e+01,  6.8495e+00, -9.9095e+00, -7.2824e+00],\n",
       "        [-1.3316e+01, -1.6496e+00,  1.7292e+00,  4.2208e+00, -9.5823e+00,\n",
       "          2.9124e+00, -1.6562e+01, -2.4449e+00,  3.3891e+00,  2.3515e+00],\n",
       "        [-2.2182e+01,  3.1330e+00,  7.6084e-02, -7.5509e-02,  1.5888e-01,\n",
       "         -6.6576e+00, -1.5365e+01,  6.3126e+00, -5.7742e-01, -2.2394e+00],\n",
       "        [-1.7679e+01, -1.4863e+00,  2.2526e-01, -7.2243e+00, -5.7710e+00,\n",
       "         -5.2830e+00, -2.3855e+01, -8.3248e-02, -2.7367e+00, -7.5560e+00],\n",
       "        [-1.2423e+01,  3.0271e-01, -3.5469e+00,  5.8432e+00, -9.8110e+00,\n",
       "          1.0560e+00, -1.6996e+01,  9.7625e+00, -1.1597e+01,  3.3472e-01],\n",
       "        [-1.2038e+01,  5.8299e+00,  5.7971e+00, -4.1036e+00, -8.2540e+00,\n",
       "          4.0422e-01, -2.2727e+01, -6.0133e+00, -3.7733e-02, -5.2200e+00],\n",
       "        [-1.8319e+01,  2.9868e+00, -7.6004e+00,  2.8837e-01, -9.0309e+00,\n",
       "         -1.0991e+01, -1.5646e+01,  4.9274e+00, -9.7837e+00,  2.5657e+00],\n",
       "        [-9.2068e+00, -3.7448e+00, -5.8524e+00, -8.9223e-01, -7.7495e+00,\n",
       "         -4.0472e+00, -2.8797e+01,  2.6659e+00,  2.9175e+00,  4.4201e+00],\n",
       "        [-2.2066e+01, -3.0843e+00,  8.3259e+00, -6.9412e+00, -9.7604e+00,\n",
       "          1.6290e+00, -1.6908e+01,  3.2405e+00, -1.0332e+01, -4.6348e+00],\n",
       "        [-2.2004e+01,  5.2609e+00, -2.8050e+00,  3.5382e+00, -1.0298e+00,\n",
       "         -1.0292e+01, -1.7124e+01,  6.2015e+00, -9.4439e+00, -7.8555e+00],\n",
       "        [-1.6633e+01,  8.4711e+00,  4.2946e+00, -1.3357e+00, -3.9130e+00,\n",
       "         -4.3673e+00, -2.4165e+01,  7.9238e+00,  8.6504e+00, -7.5589e-01],\n",
       "        [-1.2591e+01,  4.8698e+00,  8.2466e-01, -3.6411e+00, -4.7589e+00,\n",
       "         -2.8202e+00, -2.1963e+01,  8.1796e-01, -1.1760e+00, -1.8185e+00]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Solution\n",
    "def activation(x):\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "# Flatten the input images\n",
    "inputs = images.view(images.shape[0], -1)\n",
    "\n",
    "# Create parameters\n",
    "w1 = torch.randn(784, 256)\n",
    "b1 = torch.randn(256)\n",
    "\n",
    "w2 = torch.randn(256, 10)\n",
    "b2 = torch.randn(10)\n",
    "\n",
    "h = activation(torch.mm(inputs, w1) + b1)\n",
    "\n",
    "out = torch.mm(h, w2) + b2\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95826af5",
   "metadata": {},
   "source": [
    "现在网络有 10 个输出了。我们向网络中传入一个图像，并获得类别概率分布，告诉我们图像最有可能属于哪个数字/类别。结果如下所示：\n",
    "<img src='assets/image_distribution.png' width=500px>\n",
    "\n",
    "可以看出每个类别的概率大致相等。这是未训练网络的结果，网络尚未见过任何数据，因此返回均匀分布，每个类别的概率相等。\n",
    "\n",
    "可以用 [**softmax** 函数]计算概率分布(https://en.wikipedia.org/wiki/Softmax_function)。数学公式为：\n",
    "\n",
    "$$\n",
    "\\Large \\sigma(x_i) = \\cfrac{e^{x_i}}{\\sum_k^K{e^{x_k}}}\n",
    "$$\n",
    "\n",
    "它会将每个输入 $x_i$ 都缩放到 0 和 1 之间并标准化值，得出标准概率分布，其中概率总和是 1。\n",
    "\n",
    "> **练习：**实现一个进行 softmax 运算的函数 `softmax` ，并针对批次中的每个样本返回概率分布。注意，在运算时需要注意形状。如果有一个张量 `a` 的形状为 `(64, 10)`，另一个张量 `b` 的形状为 `(64,)`，进行 `a/b` 运算将出错，因为 PyTorch 会对列进行除法运算（称为广播），但是大小不匹配。提示：对于 64 个样本中的每个样本，你可以除以一个值，即分母中的和。因此需要使 `b` 变形为 `(64, 1)`。这样的话，PyTorch 将使 `a` 中每行的10 个值除以 `b` 中每行的一个值。另外，要注意求和的方式。你要在 `torch.sum` 中定义 `dim` 。`dim=0` 会对行求和，而 `dim=1` 会对列求和。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8f71a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "## Solution\n",
    "def softmax(x):\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x), dim=1).view(-1, 1)\n",
    "\n",
    "probabilities = softmax(out)\n",
    "\n",
    "# Does it have the right shape? Should be (64, 10)\n",
    "print(probabilities.shape)\n",
    "# Does it sum to 1?\n",
    "print(probabilities.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fa36a4",
   "metadata": {},
   "source": [
    "## 通过 PyTorch 构建网络\n",
    "\n",
    "PyTorch 提供了`nn`模块，大大地简化了网络构建过程。我将演示如何构建上述同一个网络，即包含 784 个输入、256 个隐藏单元、10 个输出单元和一个 softmax 输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "902be6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec73d997",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "        # Define sigmoid activation and softmax output \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the input tensor through each of our operations\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7019587c",
   "metadata": {},
   "source": [
    "分步讲解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f05024d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (2511390034.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_1064927/2511390034.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    class Network(nn.Module):\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "class Network(nn.Module):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b46f1f",
   "metadata": {},
   "source": [
    "先继承 `nn.Module`。与 `super().__init__()` 相结合，创建一个跟踪架构的类，并提供大量有用的方法和属性。注意，在为网络创建类时，必须继承 `nn.Module`。类可以随意命名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f373c7c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1064927/1235907968.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "self.hidden = nn.Linear(784, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf5c7b9",
   "metadata": {},
   "source": [
    "这行创建一个线性转换模块 $x\\mathbf{W} + b$，其中有 784 个输入和 256 个输出，并赋值给 `self.hidden`。该模块会自动创建权重和偏差张量，供我们在 `forward` 方法中使用。创建网络 (`net`) 后，你可以使用 `net.hidden.weight` 和 `net.hidden.bias` 访问权重和偏差张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12515ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
