{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c81f038c",
   "metadata": {},
   "source": [
    "# 通过 PyTorch 构建神经网络\n",
    "\n",
    "深度学习网络一般量级都很大，包含数百个层级，这也是为什么叫“深度”学习网络。你可以像在上个 notebook 展示的一样，仅使用权重矩阵构建深度网络，但是这通常很繁琐并且不好实施。PyTorch 有一个很方便的模块 `nn`，可以有效地构建大型神经网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e6c4b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary packages\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBacked.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch \n",
    "\n",
    "import helper\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a445d3e7",
   "metadata": {},
   "source": [
    " 现在我们要构建一个大型网络，并用它解决识别图像中的文字的这一难题。我们将使用 MNIST 数据集，这个数据集由灰色的手写数字组成。每个图像都是 28x28，如以下示例所示：\n",
    "\n",
    "<img src='assets/mnist.png'>\n",
    "\n",
    "我们的目标是构建一个神经网络，可以预测图像中的数字。\n",
    "\n",
    "首先，我们需要获取数据集。这些数据位于 `torchvision` 软件包中。以下代码将下载 MNIST 数据集，然后为我们创建训练数据集和测试数据集。不用太在意细节内容，稍后会详细学习的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c68bb594",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this cell\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72cd99c",
   "metadata": {},
   "source": [
    "我们将训练数据加载到 `trainloader` 中，并使用 `iter(trainloader)` 使其变成迭代器。之后，我们将用它循环访问数据集以进行训练，例如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff5e2f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image, label in trainloader:\n",
    "#     ## do things with images and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c4def6",
   "metadata": {},
   "source": [
    "我在创建 `trainloader` 时，将批次大小设为 64，并设置为 `shuffle=True`。批次大小是指我们在一次迭代中从数据加载器获取并经过网络的图像数量。`shuffle=True` 表示每次重新访问数据加载器时，随机重排数据集。但是现在我仅获取第一批数据，以便查看数据。从下方可以看出，`images` 是一个张量，大小为 `(64, 1, 28, 28)`。因此，每批有 64 个图像，图像有 1 个颜色通道，共有 28x28 个图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c104d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a047e4",
   "metadata": {},
   "source": [
    "下面是一个图像示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6250dfdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d30f5b3",
   "metadata": {},
   "source": [
    "![png](output_7_0.png)\n",
    "\n",
    "\n",
    "首先，我们要使用权重矩阵和矩阵乘法，用此数据集构建一个简单的网络。然后，我们将学习如何使用 PyTorch 的 `nn` 模块构建该网络。\n",
    "\n",
    "神经网络又称为*全连接*或*密集*网络。一个层级中的每个单元都与下个层级中的每个单元相连。在全连接网络中，每个层级的输入必须是一维向量（可以作为一批样本堆叠为二维张量）。但是，我们的图像是 28x28 二维张量，因此我们需要将其转换为一维向量。考虑到大小问题，我们需要将形状为 `(64, 1, 28, 28)` 的批次图像变形为 `(64, 784)`，784 等于 28 x 28。这一步通常称为*扁平化*，我们将二维图像扁平化为一维向量。\n",
    "\n",
    "之前，我们试过了构建具有一个输出单元的简单网络。现在，我们需要 10 个输出单元，每个数字对应一个单元。如果要预测出图像中显示的数字，我们必须计算该图像属于任何数字或类别的概率。我们会得到一个离散概率分布，告诉我们图像最有可能属于哪个类别。这就是说，我们需要 10 个输出单元，对应 10 个类别（数字）。下面讲解如何将网络输出转换为概率分布。\n",
    "\n",
    "> **练习：**将 `images`扁平化。然后构建一个多层网络，有 784 个输入单元、256 个隐藏单元和 10 个输出单元，并对权重和偏差使用随机张量。目前，我们对隐藏层使用 S 型激活函数。输出层暂时不需要激活函数，下一步我们将添加计算概率分布的激活函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e80df560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.3814e+00,  3.6992e+00,  4.3981e+00,  3.5682e+00, -1.3340e+01,\n",
       "         -4.0860e+00, -1.2888e+01, -9.5089e+00,  7.4986e+00, -1.4207e+01],\n",
       "        [-3.8963e+00,  6.9007e-01,  1.2019e+01,  1.0975e+00, -1.7923e+00,\n",
       "          1.0741e+01, -2.5624e-01, -1.1026e+01,  1.2913e-01,  8.8421e-02],\n",
       "        [ 7.0302e+00,  5.0117e+00,  1.4567e+01, -6.6964e+00, -8.4364e+00,\n",
       "          1.5068e+01, -9.2447e+00, -1.3160e+01, -1.8048e+00, -5.7882e+00],\n",
       "        [ 2.3229e+00,  6.0134e+00,  5.8739e+00,  2.9848e+00, -1.5664e+01,\n",
       "         -6.7006e+00, -1.0050e+01, -1.2500e+01, -4.3810e+00,  2.7344e+00],\n",
       "        [ 2.3337e+00, -1.6100e+00,  7.5078e+00, -1.1406e+01, -6.0361e+00,\n",
       "          1.7714e+00, -4.3577e+00, -3.9075e+00,  6.1717e+00,  2.9459e+00],\n",
       "        [-2.9607e+00,  9.7809e+00,  5.7045e+00,  5.5097e+00, -6.6187e+00,\n",
       "          1.2002e+00, -3.3399e+00, -1.4616e+01, -1.3614e+00, -8.6246e+00],\n",
       "        [-1.7457e+00,  1.1201e+00,  5.6937e-01, -7.3845e+00, -1.1975e+01,\n",
       "         -9.8724e-01, -1.4690e+00, -1.3128e+01,  6.0036e+00, -6.7844e+00],\n",
       "        [-5.1390e+00,  1.1602e+01,  9.3979e+00,  1.2117e+01, -1.1946e+01,\n",
       "         -7.7314e+00, -2.1609e+00, -1.8504e+01,  5.9784e+00, -4.5237e+00],\n",
       "        [ 8.4108e+00,  7.6126e+00,  4.1280e+00,  6.7640e+00, -1.2928e+01,\n",
       "          2.8745e-01, -9.3924e+00, -3.5235e+00,  4.5887e+00, -7.3873e+00],\n",
       "        [ 3.6746e+00,  9.5073e+00,  6.3527e+00,  6.6336e+00, -4.1491e+00,\n",
       "         -5.2382e+00, -8.2843e-01, -1.1298e+01,  6.1236e+00,  2.3205e+00],\n",
       "        [ 2.8385e+00,  2.4194e-01, -2.7519e+00, -6.4642e+00, -9.9018e+00,\n",
       "         -5.4295e+00, -1.3473e+00, -1.9082e+01,  8.3108e+00, -1.9363e+00],\n",
       "        [-1.7984e+00,  8.5819e+00, -3.1178e+00, -5.1877e+00, -1.3947e+01,\n",
       "         -5.0855e+00, -2.2599e+00, -1.1671e+01, -4.5990e+00, -9.0357e+00],\n",
       "        [ 6.1956e+00,  2.3828e+00,  3.9193e+00, -6.8478e+00, -1.4963e+01,\n",
       "          2.4411e+00, -1.6763e+00, -1.0780e+01,  4.5680e+00, -5.3987e+00],\n",
       "        [-7.4457e-01,  5.1155e+00,  1.2607e+01,  6.7752e+00, -4.3719e+00,\n",
       "          3.6065e+00, -1.2805e+00, -4.6723e+00, -3.0621e+00,  6.6208e+00],\n",
       "        [ 2.5241e+00,  9.0756e+00,  4.7048e-01,  6.0941e+00, -5.1959e+00,\n",
       "          3.7688e-02, -8.2611e+00, -9.1735e+00, -2.1277e+00,  1.1209e+00],\n",
       "        [ 6.1059e+00,  5.0212e+00, -9.1245e+00, -6.6151e+00,  3.0509e+00,\n",
       "          3.1732e+00, -1.1327e+01, -5.7205e+00, -1.0189e+00, -3.0389e+00],\n",
       "        [-1.4430e+01,  6.8404e+00,  8.9753e+00, -1.3547e+01, -1.3932e+01,\n",
       "         -1.2558e+00,  7.4719e+00, -1.9218e+00,  4.0736e+00, -1.6298e+01],\n",
       "        [-4.0449e+00, -2.6073e+00,  2.0306e+01,  3.6295e+00, -1.1589e+01,\n",
       "         -1.6702e+00, -4.7724e+00, -9.1960e+00,  5.5547e-02, -4.2496e+00],\n",
       "        [ 1.6408e+00,  3.5191e+00, -1.3484e-02, -2.3411e+00, -1.0387e+01,\n",
       "         -1.9788e+00,  3.7824e+00, -1.7499e+01,  2.6432e+00, -3.2183e+00],\n",
       "        [ 4.6585e+00,  7.6914e+00,  5.6164e+00,  9.7268e-01, -1.0272e+01,\n",
       "          1.2134e+00, -4.5450e-01, -1.6555e+01,  7.9190e+00, -4.0281e-01],\n",
       "        [-2.6245e+00,  9.3881e+00,  1.2978e+01,  6.3683e+00, -4.8021e+00,\n",
       "         -4.0986e+00,  6.7688e+00, -1.1504e+01,  9.5865e+00, -1.2950e+00],\n",
       "        [-4.0180e+00,  9.6958e+00,  8.8014e+00,  4.9885e+00, -1.1023e+01,\n",
       "         -7.8864e-01, -8.6253e+00, -1.2860e+01,  6.0804e+00, -6.9946e+00],\n",
       "        [ 7.0993e+00,  4.3844e+00,  9.8630e+00,  5.3767e+00, -1.0794e+01,\n",
       "          1.1257e+00, -5.8793e+00, -1.8292e+01,  1.1169e+01, -6.1172e+00],\n",
       "        [-2.9454e+00,  8.4667e+00,  1.5747e+01, -4.2880e-02, -7.6139e+00,\n",
       "          9.8419e+00, -9.5348e+00, -4.3826e+00, -6.7381e+00, -8.1896e+00],\n",
       "        [-8.0197e+00,  4.7960e+00,  2.3814e+00, -1.6698e+00, -1.2707e+01,\n",
       "         -6.8555e-01,  2.9616e+00, -1.3628e+01,  6.9502e+00, -7.3511e+00],\n",
       "        [-3.0523e+00,  1.3207e+00,  1.0753e+01, -3.5704e+00, -1.0536e+01,\n",
       "          1.1764e+00,  2.2305e+00, -1.0285e+01,  3.0310e+00, -5.3562e-01],\n",
       "        [ 6.0291e+00,  1.5151e+01,  4.0486e+00,  6.3218e+00, -8.1604e+00,\n",
       "         -1.0075e+01, -4.1499e+00, -1.3667e+01, -1.0478e+00, -7.8937e+00],\n",
       "        [-3.7232e+00,  6.6465e+00, -4.0256e-01,  1.9620e+00, -1.8358e+01,\n",
       "         -2.0193e+00, -3.4822e+00, -7.5815e+00, -4.1094e+00, -3.8494e+00],\n",
       "        [ 5.8274e+00,  1.0180e+01,  9.3782e+00,  3.9353e+00, -1.3361e+01,\n",
       "          8.8141e+00, -9.0912e+00, -2.5236e+01,  1.6667e+00, -1.5242e+00],\n",
       "        [-3.5002e+00,  9.1834e+00,  1.3575e+01,  5.1780e+00, -9.3727e+00,\n",
       "         -7.6274e-03, -1.0400e+01, -5.5004e+00,  1.1625e-03, -5.4995e+00],\n",
       "        [ 2.3658e+00,  4.2992e+00,  1.3594e+01,  5.7171e+00, -4.1153e+00,\n",
       "          4.9529e+00,  5.9470e-01, -1.6684e+01,  4.7460e+00, -9.1095e+00],\n",
       "        [ 1.6729e-01,  1.0655e+01,  6.1494e+00,  2.4036e+00, -1.0328e+01,\n",
       "         -2.5155e+00, -5.9234e+00, -5.7904e+00, -1.4080e+00, -2.7579e+00],\n",
       "        [-2.5773e+00,  2.1665e+00,  1.4053e+01, -3.5112e+00, -2.0564e+01,\n",
       "          3.0563e+00,  4.0750e+00, -1.0943e+00, -5.1518e+00, -8.6598e+00],\n",
       "        [ 1.4590e+00, -1.8624e-01,  7.3659e+00,  1.4046e+00, -1.4436e+01,\n",
       "         -2.5855e+00, -5.3088e-01, -1.4630e+01, -3.1149e-01,  1.6399e+00],\n",
       "        [ 1.0638e+01,  3.9173e+00,  6.1486e+00, -5.0543e+00, -1.3387e+01,\n",
       "         -6.6751e+00, -7.6935e+00, -8.3741e+00,  1.1732e+01,  3.2153e+00],\n",
       "        [-3.7837e+00,  8.7979e+00,  8.2347e+00, -2.1886e+00,  4.6105e+00,\n",
       "         -2.5739e+00,  5.3211e+00, -6.7701e+00,  3.9634e+00, -1.6259e+00],\n",
       "        [ 4.7217e+00,  3.2257e+00,  2.2353e+00, -5.6805e+00, -8.9616e+00,\n",
       "         -6.6667e+00, -1.8349e+00, -1.6703e+01,  6.0437e+00, -6.4929e+00],\n",
       "        [-1.5043e+00,  7.1987e+00,  8.1798e+00,  2.1895e+00, -2.3907e+00,\n",
       "          2.9973e+00, -8.9935e+00, -1.3673e+01,  7.0815e+00, -7.4334e-01],\n",
       "        [-1.3880e+00, -9.5975e-01,  2.0857e+01,  2.2232e-01, -1.4023e+01,\n",
       "          5.9386e+00,  4.5294e+00, -1.0088e+01, -7.9727e-01, -4.0007e+00],\n",
       "        [ 6.5618e+00,  8.2639e+00,  3.0972e+00, -4.3199e+00, -9.1718e+00,\n",
       "         -4.1596e+00, -8.9689e+00,  4.0841e-01,  6.8156e+00,  3.0552e+00],\n",
       "        [-2.5292e+00,  1.4358e+01,  6.0800e+00,  8.2522e+00, -3.4143e+00,\n",
       "         -3.6748e+00, -8.3449e+00, -1.9077e+01,  6.0421e+00, -1.2817e+01],\n",
       "        [ 1.8215e+00,  7.8682e+00,  8.9040e+00,  1.1885e+00, -6.6569e+00,\n",
       "          2.7229e-01, -4.1865e+00, -1.3453e+01,  5.6225e+00, -8.9900e+00],\n",
       "        [-4.6929e-01,  2.2969e-01,  4.0859e+00,  9.5118e+00, -6.9261e+00,\n",
       "          7.2635e+00,  1.6232e+00, -7.5633e+00,  2.8303e+00,  2.3971e+00],\n",
       "        [-9.2802e-01, -1.6198e+00, -5.4279e+00,  3.9430e+00, -1.8447e+01,\n",
       "         -6.9872e+00,  1.9630e+00, -1.4581e+01,  9.7206e+00, -9.9572e-01],\n",
       "        [-4.9899e-01,  7.0990e+00,  1.3070e+01,  9.8265e-01, -1.0682e+01,\n",
       "          1.4515e+00, -6.3852e+00, -1.0383e+01,  1.2523e+01,  3.2537e+00],\n",
       "        [-1.1154e-01,  1.0348e+01,  4.1179e+00, -1.9612e+00, -1.4841e+01,\n",
       "         -1.4177e+00, -1.7620e+00, -1.6374e+01, -9.9307e-01, -1.1761e+01],\n",
       "        [-6.7393e+00,  4.1368e+00,  8.3519e+00, -1.6974e+01, -1.8907e+01,\n",
       "          1.0987e+01, -2.7720e+00, -7.7894e+00,  3.4420e+00,  4.5963e+00],\n",
       "        [ 3.6314e+00,  1.9565e+00,  2.9930e+00,  8.3129e-01, -1.2754e+01,\n",
       "         -2.3105e+00, -8.9484e+00, -1.4016e+01,  1.3399e+01, -5.6995e+00],\n",
       "        [ 1.7843e+00,  2.5627e+00, -1.1362e+00,  2.7523e+00, -1.7427e+01,\n",
       "         -1.2419e+01, -1.2377e+01, -1.1051e+01,  1.0227e+01, -6.4499e+00],\n",
       "        [-1.7921e+00,  1.0471e+01,  1.8362e+01,  3.5574e+00, -1.5505e+01,\n",
       "         -1.9773e+00, -5.3215e+00, -9.3193e+00, -2.8915e+00, -4.3187e+00],\n",
       "        [-2.4901e+00,  8.1595e+00, -1.0459e+00, -4.2803e+00, -1.0125e+01,\n",
       "         -3.6397e+00,  6.1108e-01, -1.8774e+01,  7.2002e+00, -1.2905e+01],\n",
       "        [-1.4843e+00,  2.7225e+00,  2.8407e+00,  1.3959e+00, -1.4780e+01,\n",
       "          3.3293e+00, -5.8395e+00, -8.0395e+00, -3.4662e+00, -5.9258e-01],\n",
       "        [ 1.1547e+01,  3.0467e+00,  2.3307e+00, -6.1730e+00, -1.6619e+01,\n",
       "          5.6817e-01, -1.8098e+00, -7.5948e+00, -3.6627e+00,  6.6711e+00],\n",
       "        [ 3.0112e+00,  2.6917e+00, -3.7683e+00,  9.3430e+00, -1.2240e+01,\n",
       "          3.0603e+00, -2.5920e+00, -9.5057e+00,  5.0026e+00,  1.5077e+00],\n",
       "        [-2.6882e+00,  1.1344e+00,  5.6625e+00, -1.0538e+01, -2.6634e+00,\n",
       "          2.4747e+00, -1.1018e+01, -7.9593e+00, -4.5671e+00,  1.1219e+00],\n",
       "        [ 7.8558e+00,  5.0102e+00,  7.4392e+00,  1.7529e-02, -4.5375e+00,\n",
       "          1.7599e+00, -8.0752e+00, -1.1724e+01, -2.8259e-01, -3.3819e+00],\n",
       "        [-2.3585e+00,  5.8909e+00,  6.0366e+00, -3.2813e+00, -7.5356e+00,\n",
       "          8.1680e+00, -6.2773e+00, -1.4531e+01, -7.4733e-01, -6.4404e+00],\n",
       "        [-2.8064e+00,  8.9838e+00,  1.6135e+01,  1.7496e+00, -1.1440e+01,\n",
       "          6.2354e+00, -6.6092e+00,  2.1284e+00,  9.2178e-01, -3.9542e+00],\n",
       "        [ 6.7786e+00,  3.8881e+00, -3.3092e+00, -6.4918e+00, -1.1211e+01,\n",
       "          1.8911e-01, -1.0491e+01, -4.2151e+00, -5.9401e+00,  2.8220e-01],\n",
       "        [-3.1934e+00,  8.4007e+00,  8.4060e+00, -5.6403e-01, -9.8524e+00,\n",
       "          8.0140e-01, -4.8412e+00, -1.0005e+01,  2.3738e+00, -8.1533e-01],\n",
       "        [ 4.8956e-01,  1.6848e+00,  1.0670e+01, -5.2042e+00, -7.5065e+00,\n",
       "         -5.6317e+00, -1.1650e+00, -1.1350e+01,  8.1953e+00, -5.8098e+00],\n",
       "        [ 2.4854e+00, -1.7747e-01,  1.4331e+01,  2.8726e+00, -9.3010e+00,\n",
       "         -3.8816e+00, -3.4234e+00, -1.2529e+01,  3.5934e+00, -3.5493e+00],\n",
       "        [ 1.5653e+00,  3.2874e+00,  1.1762e+01, -8.3417e+00, -1.1667e+01,\n",
       "         -3.4084e+00, -1.1123e+01, -1.4214e+01, -4.0097e+00, -2.0144e-01],\n",
       "        [-2.4407e+00,  1.3683e+01,  3.0503e+00,  8.6089e+00, -6.3166e+00,\n",
       "         -1.5006e+01, -1.1820e+01, -1.8011e+01,  9.4739e+00, -7.8920e-01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Solution\n",
    "def activation(x):\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "# Flatten the input images\n",
    "inputs = images.view(images.shape[0], -1)\n",
    "\n",
    "# Create parameters\n",
    "w1 = torch.randn(784, 256)\n",
    "b1 = torch.randn(256)\n",
    "\n",
    "w2 = torch.randn(256, 10)\n",
    "b2 = torch.randn(10)\n",
    "\n",
    "h = activation(torch.mm(inputs, w1) + b1)\n",
    "\n",
    "out = torch.mm(h, w2) + b2\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95826af5",
   "metadata": {},
   "source": [
    "现在网络有 10 个输出了。我们向网络中传入一个图像，并获得类别概率分布，告诉我们图像最有可能属于哪个数字/类别。结果如下所示：\n",
    "<img src='assets/image_distribution.png' width=500px>\n",
    "\n",
    "可以看出每个类别的概率大致相等。这是未训练网络的结果，网络尚未见过任何数据，因此返回均匀分布，每个类别的概率相等。\n",
    "\n",
    "可以用 [**softmax** 函数]计算概率分布(https://en.wikipedia.org/wiki/Softmax_function)。数学公式为：\n",
    "\n",
    "$$\n",
    "\\Large \\sigma(x_i) = \\cfrac{e^{x_i}}{\\sum_k^K{e^{x_k}}}\n",
    "$$\n",
    "\n",
    "它会将每个输入 $x_i$ 都缩放到 0 和 1 之间并标准化值，得出标准概率分布，其中概率总和是 1。\n",
    "\n",
    "> **练习：**实现一个进行 softmax 运算的函数 `softmax` ，并针对批次中的每个样本返回概率分布。注意，在运算时需要注意形状。如果有一个张量 `a` 的形状为 `(64, 10)`，另一个张量 `b` 的形状为 `(64,)`，进行 `a/b` 运算将出错，因为 PyTorch 会对列进行除法运算（称为广播），但是大小不匹配。提示：对于 64 个样本中的每个样本，你可以除以一个值，即分母中的和。因此需要使 `b` 变形为 `(64, 1)`。这样的话，PyTorch 将使 `a` 中每行的10 个值除以 `b` 中每行的一个值。另外，要注意求和的方式。你要在 `torch.sum` 中定义 `dim` 。`dim=0` 会对行求和，而 `dim=1` 会对列求和。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8f71a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "## Solution\n",
    "def softmax(x):\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x), dim=1).view(-1, 1)\n",
    "\n",
    "probabilities = softmax(out)\n",
    "\n",
    "# Does it have the right shape? Should be (64, 10)\n",
    "print(probabilities.shape)\n",
    "# Does it sum to 1?\n",
    "print(probabilities.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fa36a4",
   "metadata": {},
   "source": [
    "## 通过 PyTorch 构建网络\n",
    "\n",
    "PyTorch 提供了`nn`模块，大大地简化了网络构建过程。我将演示如何构建上述同一个网络，即包含 784 个输入、256 个隐藏单元、10 个输出单元和一个 softmax 输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "902be6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec73d997",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "        # Define sigmoid activation and softmax output \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the input tensor through each of our operations\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7019587c",
   "metadata": {},
   "source": [
    "分步讲解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f05024d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class Network(nn.Module):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b46f1f",
   "metadata": {},
   "source": [
    "先继承 `nn.Module`。与 `super().__init__()` 相结合，创建一个跟踪架构的类，并提供大量有用的方法和属性。注意，在为网络创建类时，必须继承 `nn.Module`。类可以随意命名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f373c7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#self.hidden = nn.Linear(784, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf5c7b9",
   "metadata": {},
   "source": [
    "这行创建一个线性转换模块 $x\\mathbf{W} + b$，其中有 784 个输入和 256 个输出，并赋值给 `self.hidden`。该模块会自动创建权重和偏差张量，供我们在 `forward` 方法中使用。创建网络 (`net`) 后，你可以使用 `net.hidden.weight` 和 `net.hidden.bias` 访问权重和偏差张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12515ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#self.output = nn.Linear(256, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccb4bb5",
   "metadata": {},
   "source": [
    "同样，这里会创建另一个有 256 个输入和 10 个输出的线性转换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fae60979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#self.sigmoid = nn.Sigmoid()\n",
    "#self.softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33dad48",
   "metadata": {},
   "source": [
    "然后，我定义了 S 型激活函数和 softmax 输出的运算。在 `nn.Softmax(dim=1)` 中设置 `dim=1` 会计算各个列的 softmax 值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f22aecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def forward(self, x):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece2ee84",
   "metadata": {},
   "source": [
    "用 `nn.Module` 创建的 PyTorch 网络必须定义 `forward` 方法。它会接受一个张量 `x` 并将其传入你在 `__init__` 方法中定义的运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fffaeef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = self.hidden(x)\n",
    "#x = self.sigmoid(x)\n",
    "#x = self.output(x)\n",
    "#x = self.softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb1920c",
   "metadata": {},
   "source": [
    "我们将输入张量 `x` 传入重新赋值给 `x` 的每个运算。可以看出输入张量经过隐藏层，然后经过 S 型函数、输出层，最终经过 softmax 函数。.变量可以命名为任何名称，只要运算的输入和输出与你要构建的网络架构匹配即可。你在 `__init__` 方法中的定义顺序不重要，但是需要在 `forward` 方法中正确地设定运算顺序。\n",
    "\n",
    "现在我们可以创建一个 `Network` 对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa138211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the network and look at it's text representation\n",
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8111e953",
   "metadata": {},
   "source": [
    "你可以使用 `torch.nn.functional` 模块来更简练清晰地定义网络。这是最常见的网络定义方式，因为很多运算是简单的元素级函数。我们通常将此模块导入为 `F`，即 `import torch.nn.functional as F`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a288ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class NetWork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Input to hidden layer linear transformation\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Hidden layer with sigmoid activation\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        # Output layer with softmax activation\n",
    "        x = F.softmax(self.output(x), dim = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83860f4d",
   "metadata": {},
   "source": [
    "### 激活函数\n",
    "\n",
    "到目前为止，我们只学习了 softmax 激活函数，但是通常任何函数都可以用作激活函数。但是，要使网络能逼近非线性函数，激活函数必须是非线性函数。下面是一些常见的激活函数示例：Tanh（双曲正切）和 ReLU（修正线性单元）。\n",
    "\n",
    "<img src=\"assets/activation.png\" width=700px>\n",
    "\n",
    "在实践中，ReLU 几乎一直用作隐藏层激活函数。\n",
    "\n",
    "### 构建神经网络\n",
    "\n",
    "<img src=\"assets/mlp_mnist.png\" width=600px>\n",
    "\n",
    "> **练习：**请创建如下网络：输入层有 784 个单元，然后是有 128 个单元的隐藏层和一个 ReLU 激活函数，接着是有 64 个单元的隐藏层和一个 ReLU 激活函数，最终是一个应用 softmax 激活函数的输出层（如上所示）。你可以通过 `nn.ReLU` 模块或 `F.relu` 函数应用 ReLU 激活函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26ab35db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NetWork(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Solution\n",
    "\n",
    "class NetWork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Defining the layers, 128, 64, 10 units each\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''Forward pass through the nerwork, return the output logits'''\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.softmax(x, dim = 1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = NetWork()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b58811",
   "metadata": {},
   "source": [
    "### 初始化权重和偏差\n",
    "\n",
    "权重和偏差会自动初始化，但是你可以自定义它们的初始化方式。权重和偏差是附加到所定义层级上的张量，例如，你可以通过 `model.fc1.weight` 获取权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a33dbb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0325,  0.0229, -0.0223,  ..., -0.0181, -0.0294, -0.0287],\n",
      "        [ 0.0193,  0.0133, -0.0202,  ...,  0.0165, -0.0199, -0.0001],\n",
      "        [-0.0137,  0.0081,  0.0320,  ...,  0.0199, -0.0328,  0.0154],\n",
      "        ...,\n",
      "        [ 0.0082, -0.0066,  0.0235,  ...,  0.0189,  0.0187,  0.0153],\n",
      "        [-0.0346, -0.0039,  0.0219,  ...,  0.0186, -0.0109, -0.0328],\n",
      "        [-0.0271,  0.0054, -0.0048,  ...,  0.0135,  0.0037, -0.0303]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-2.8198e-02,  4.4907e-03, -1.5443e-02,  2.8066e-02,  3.3863e-02,\n",
      "        -2.6143e-03,  2.5784e-02,  1.1134e-02, -6.8966e-03, -1.5406e-02,\n",
      "         2.5191e-03, -2.2019e-02,  3.4470e-02,  5.8445e-03, -6.3876e-03,\n",
      "         3.4054e-02,  3.2580e-02, -1.6409e-02, -1.7206e-02, -2.3633e-02,\n",
      "         2.9765e-02,  7.0968e-03,  1.4291e-02, -1.2009e-02,  3.3798e-02,\n",
      "         2.4752e-02, -3.1493e-03,  3.4345e-02, -3.1577e-02, -1.2808e-02,\n",
      "        -9.7646e-03,  3.0621e-02, -2.1288e-02,  2.5617e-02, -6.4774e-03,\n",
      "         3.5143e-02, -3.1690e-02,  2.8066e-02,  3.2700e-02,  2.0251e-02,\n",
      "        -3.2479e-02, -2.3868e-02, -3.1031e-02, -2.8009e-03,  2.5482e-02,\n",
      "        -1.0709e-02,  5.9244e-03, -2.9864e-02, -2.4048e-02,  3.0654e-02,\n",
      "        -3.1397e-02, -1.7679e-02, -3.4804e-02,  1.2550e-02,  2.4226e-02,\n",
      "        -3.0787e-02, -2.7914e-02, -8.9505e-03, -5.5309e-03,  5.1529e-03,\n",
      "        -2.2808e-02, -2.9414e-02, -7.4796e-03, -2.2150e-02,  2.3700e-02,\n",
      "         1.5471e-02, -3.0863e-02,  9.4219e-03,  2.8608e-02, -2.4397e-02,\n",
      "        -1.1033e-02, -1.7146e-03, -3.5135e-02, -2.6092e-02,  2.9909e-02,\n",
      "        -2.8029e-02, -2.6948e-02,  1.4763e-02,  4.4476e-03, -7.1545e-03,\n",
      "        -8.3483e-03, -1.8891e-02, -1.1638e-02, -6.9959e-03,  3.5434e-02,\n",
      "        -3.5417e-02,  1.4184e-03,  1.1865e-03, -3.4202e-02, -1.2602e-02,\n",
      "         2.7121e-02, -1.7953e-02,  1.1245e-02, -1.4289e-02,  3.1427e-02,\n",
      "         6.6458e-03, -6.1469e-03, -3.3737e-02,  2.1099e-02, -3.6611e-03,\n",
      "         9.0536e-03,  9.1334e-03,  2.7277e-02,  2.5629e-02,  1.5898e-02,\n",
      "         2.4592e-02,  2.9737e-02,  4.9529e-03,  2.0760e-02, -1.2439e-02,\n",
      "        -3.2421e-02, -3.5009e-02, -7.5809e-03,  2.3645e-02,  1.5089e-02,\n",
      "         2.6531e-02,  2.8450e-02,  3.4422e-05,  3.2064e-02,  2.9477e-04,\n",
      "         8.9030e-03,  2.9959e-03, -8.0993e-03,  2.0150e-02, -2.6821e-02,\n",
      "        -1.2449e-02,  3.1153e-02, -6.3486e-03], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.fc1.weight)\n",
    "print(model.fc1.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d832ed",
   "metadata": {},
   "source": [
    "要自定义初始化过程，我们需要原地修改这些张量。这些实际上是 autograd 变量，因此我们需要使用 model.fc1.weight.data 获取实际张量。获得张量后，我们可以用 0（对于偏差）或随机正常值填充这些张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2776b9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set biases to all zeros\n",
    "model.fc1.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60eb31bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0076,  0.0101,  0.0025,  ...,  0.0069,  0.0239, -0.0024],\n",
       "        [-0.0023, -0.0022, -0.0007,  ...,  0.0040, -0.0279, -0.0050],\n",
       "        [-0.0026,  0.0059,  0.0099,  ..., -0.0010, -0.0012, -0.0038],\n",
       "        ...,\n",
       "        [ 0.0005, -0.0090,  0.0049,  ..., -0.0166, -0.0027,  0.0003],\n",
       "        [-0.0058,  0.0020,  0.0128,  ..., -0.0165, -0.0048,  0.0008],\n",
       "        [-0.0029, -0.0179,  0.0082,  ..., -0.0140, -0.0051, -0.0064]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample from random normal with standard dev = 0.01\n",
    "model.fc1.weight.data.normal_(std=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540edbcd",
   "metadata": {},
   "source": [
    "### 前向传递\n",
    "\n",
    "我们已经创建好网络，看看传入图像后会发生什么。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b145181a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1086796/3499853464.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/zhDeepLearning/intro_to_pytorch/helper.py\u001b[0m in \u001b[0;36mview_classify\u001b[0;34m(img, ps, version)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0max2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0max2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_aspect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0max2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_yticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mbarh\u001b[0;34m(self, y, width, height, left, align, **kwargs)\u001b[0m\n\u001b[1;32m   2550\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'orientation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'horizontal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2551\u001b[0m         patches = self.bar(x=left, height=height, width=width, bottom=y,\n\u001b[0;32m-> 2552\u001b[0;31m                            align=align, **kwargs)\n\u001b[0m\u001b[1;32m   2553\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpatches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1412\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2342\u001b[0m         x, height, width, y, linewidth, hatch = np.broadcast_arrays(\n\u001b[1;32m   2343\u001b[0m             \u001b[0;31m# Make args iterable too.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2344\u001b[0;31m             np.atleast_1d(x), height, width, y, linewidth, hatch)\n\u001b[0m\u001b[1;32m   2345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2346\u001b[0m         \u001b[0;31m# Now that units have been converted, set the tick locations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[0;34m(subok, *args)\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_shape\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;31m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0;31m# consistently\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m     \u001b[0;31m# unfortunately, it cannot handle 32 or more arguments directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grab some data \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Resize images into a 1D vector, new shape is (batch size, color channels, image pixels) \n",
    "images.resize_(64, 1, 784)\n",
    "# or images.resize_(images.shape[0], 1, 784) to automatically get batch size\n",
    "\n",
    "# Forward pass through the network\n",
    "img_idx = 0\n",
    "ps = model.forward(images[img_idx,:])\n",
    "\n",
    "img = images[img_idx]\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56783c8",
   "metadata": {},
   "source": [
    "![png](output_28_0.png)\n",
    "\n",
    "\n",
    "是的，我们的网络还不能判断出这个数字。这是因为我们尚未训练它，所有权重都是随机的！\n",
    "\n",
    "### 使用 `nn.Sequential`\n",
    "\n",
    "PyTorch 提供了一种方便的方法来构建这类网络（其中张量按顺序执行各种运算）：`nn.Sequential` ([文档](https://pytorch.org/docs/master/nn.html#torch.nn.Sequential))。使用它来构建等效网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4b33328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (5): Softmax(dim=1)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.Softmax(dim=1))\n",
    "print(model)\n",
    "\n",
    "# Forward pass through the network and display output\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "ps = model.forward(images[0,:])\n",
    "helper.view_classify(images[0].view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe77178d",
   "metadata": {},
   "source": [
    "![png](output_30_1.png)\n",
    "\n",
    "\n",
    "通过传入相应的索引即可执行运算。例如，如果你想获得第一个线性运算并查看权重，可以使用 `model[0]`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0aacd4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=128, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0219,  0.0149, -0.0150,  ...,  0.0343,  0.0223, -0.0333],\n",
       "        [ 0.0233, -0.0024,  0.0053,  ..., -0.0236, -0.0132, -0.0207],\n",
       "        [-0.0229, -0.0222, -0.0028,  ..., -0.0073,  0.0299,  0.0177],\n",
       "        ...,\n",
       "        [-0.0229,  0.0030,  0.0340,  ...,  0.0287,  0.0053, -0.0254],\n",
       "        [-0.0179,  0.0005, -0.0183,  ...,  0.0087, -0.0177,  0.0153],\n",
       "        [-0.0033,  0.0159, -0.0169,  ..., -0.0324,  0.0353, -0.0012]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model[0])\n",
    "model[0].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307cbb8e",
   "metadata": {},
   "source": [
    "还可以传入 `OrderedDict` 以命名单个层级和运算，而不是使用递增的整数。注意，因为字典键必须是唯一的，所以_每个运算都必须具有不同的名称_。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbe7cd8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "model = nn.Sequential(OrderedDict([\n",
    "                      ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "                      ('relu1', nn.ReLU()),\n",
    "                      ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "                      ('relu2', nn.ReLU()),\n",
    "                      ('output', nn.Linear(hidden_sizes[1], output_size)),\n",
    "                      ('softmax', nn.Softmax(dim=1))]))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead5d528",
   "metadata": {},
   "source": [
    "现在你可以通过整数或名称访问层级了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4481a29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=128, bias=True)\n",
      "Linear(in_features=784, out_features=128, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(model[0])\n",
    "print(model.fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce108a1",
   "metadata": {},
   "source": [
    "在下个 notebook 中，我们将学习如何训练神经网络，以便准确预测 MNIST 图像中出现的数字。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
